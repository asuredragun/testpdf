{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (2.0.37)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from sqlalchemy) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-community in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (0.3.15)\n",
      "Requirement already satisfied: langchain in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (0.3.15)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (0.3.1)\n",
      "Requirement already satisfied: openai in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (1.59.9)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (0.11.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: pypdf in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (3.17.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community) (0.3.31)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community) (0.2.11)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (2.10.5)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from pdfplumber) (11.1.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from pdfminer.six==20231228->pdfplumber) (44.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.25.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain-community) (24.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\cristobal.ulloa\\appdata\\roaming\\python\\python311\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas sqlalchemy\n",
    "!pip install langchain-community langchain langchain-openai openai pdfplumber pandas pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo LLM (asegúrate de tener tu API key configurada)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", openai_api_key=api_key)\n",
    "# Crear un prompt para procesar tablas\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"pdf_content\"],\n",
    "    template=(\n",
    "        \"Extrae las tablas del siguiente texto del PDF y organízalas en un formato tabular JSON.\"\n",
    "        \"El texto es:\\n{pdf_content}\"\n",
    "        \"Solo devuelve el JSON, sin ```json\\n\"\n",
    "    )\n",
    ")\n",
    " \n",
    "# Crear una cadena LangChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    " \n",
    "# Directorio de entrada y archivo de salida\n",
    "pdf_directory = \"pdf\"  # Cambia a la ruta de tu directorio con los PDFs\n",
    "output_file = \"output.json\"  # Archivo de salida donde se almacenará el resultado\n",
    " \n",
    "# Crear un diccionario para almacenar los resultados de cada archivo PDF\n",
    "results = {}\n",
    " \n",
    "# Iterar sobre los archivos PDF en el directorio \"pdfs\"\n",
    "pdf_directory = \"pdf\"  # Reemplaza con la ruta correcta a tu directorio\n",
    "for filename in os.listdir(pdf_directory):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        filepath = os.path.join(pdf_directory, filename)\n",
    "        print(f\"Procesando archivo: {filename}\")\n",
    " \n",
    "        try:\n",
    "          # Cargar y leer el PDF\n",
    "          loader = PyPDFLoader(filepath)\n",
    "          documents = loader.load()\n",
    " \n",
    "          # Combinar texto del PDF\n",
    "          pdf_text = \" \".join([doc.page_content for doc in documents])\n",
    " \n",
    "          # Ejecutar el modelo para procesar el contenido del PDF\n",
    "          response = chain.run(pdf_content=pdf_text)\n",
    "          #print(response) # Imprime la respuesta JSON para cada archivo\n",
    " \n",
    "          # Guardar la respuesta JSON asociada al archivo\n",
    "          results[filename] = json.loads(response)\n",
    "          \n",
    "          \n",
    "        except Exception as e:\n",
    "          print(f\"Error al procesar {filename}: {e}\")\n",
    "          \n",
    "        try:\n",
    "                data = json.loads(response)\n",
    "\n",
    "                # Adaptar la estructura del JSON a la deseada\n",
    "                resultados_archivo = {\n",
    "                    \"nombre_archivo\": filename,\n",
    "                    \"prescripcion_medico_veterinaria\": data.get(\"prescripcion_medico_veterinaria\", {}),\n",
    "                    \"unidades_cultivo\": data.get(\"unidades_cultivo\", []),\n",
    "                    \"cantidad_total_alimento\": data.get(\"cantidad_total_alimento\", {}),\n",
    "                    \"dieta\": data.get(\"dieta\", {})  # Si solo hay una dieta, se guarda como objeto\n",
    "                }\n",
    "\n",
    "                results[filename] = resultados_archivo\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "                print(f\"Error al decodificar JSON para {filename}: {e}\")\n",
    "        except Exception as e:\n",
    "                print(f\"Error al convertir a DataFrame para {filename}: {e}\")\n",
    "# Escribir los resultados en un archivo JSON\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=4, ensure_ascii=False)\n",
    " \n",
    "print(f\"Procesamiento completado. Resultados guardados en '{output_file}'.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Procesando archivo: Agua Buena - ABR 2024.pdf\n",
      "✅ Datos de 'Agua Buena - ABR 2024.pdf' guardados en 'inten\\Agua Buena - ABR 2024.xlsx'.\n",
      "📄 Procesando archivo: Agua Buena - Declaración_SINADER_folio_1000494 - DIC 2024.pdf\n",
      "✅ Datos de 'Agua Buena - Declaración_SINADER_folio_1000494 - DIC 2024.pdf' guardados en 'inten\\Agua Buena - Declaración_SINADER_folio_1000494 - DIC 2024.xlsx'.\n",
      "📄 Procesando archivo: Agua Buena - Declaración_SINADER_folio_856717.pdf\n",
      "✅ Datos de 'Agua Buena - Declaración_SINADER_folio_856717.pdf' guardados en 'inten\\Agua Buena - Declaración_SINADER_folio_856717.xlsx'.\n",
      "📄 Procesando archivo: Agua Buena - Declaración_SINADER_folio_868652 - FEB 2024.pdf\n",
      "✅ Datos de 'Agua Buena - Declaración_SINADER_folio_868652 - FEB 2024.pdf' guardados en 'inten\\Agua Buena - Declaración_SINADER_folio_868652 - FEB 2024.xlsx'.\n",
      "📄 Procesando archivo: Agua Buena - Declaración_SINADER_folio_888389 - MAR 2024.pdf\n",
      "✅ Datos de 'Agua Buena - Declaración_SINADER_folio_888389 - MAR 2024.pdf' guardados en 'inten\\Agua Buena - Declaración_SINADER_folio_888389 - MAR 2024.xlsx'.\n",
      "📄 Procesando archivo: Agua Buena - Declaración_SINADER_folio_917166 - MAY 2024.pdf\n",
      "✅ Datos de 'Agua Buena - Declaración_SINADER_folio_917166 - MAY 2024.pdf' guardados en 'inten\\Agua Buena - Declaración_SINADER_folio_917166 - MAY 2024.xlsx'.\n",
      "📄 Procesando archivo: Agua Buena - Declaración_SINADER_folio_929364 - JUN 2024.pdf\n",
      "✅ Datos de 'Agua Buena - Declaración_SINADER_folio_929364 - JUN 2024.pdf' guardados en 'inten\\Agua Buena - Declaración_SINADER_folio_929364 - JUN 2024.xlsx'.\n",
      "📄 Procesando archivo: Agua Buena - Declaración_SINADER_folio_952693 - AGO 2024.pdf\n",
      "✅ Datos de 'Agua Buena - Declaración_SINADER_folio_952693 - AGO 2024.pdf' guardados en 'inten\\Agua Buena - Declaración_SINADER_folio_952693 - AGO 2024.xlsx'.\n",
      "📄 Procesando archivo: Agua Buena - Declaración_SINADER_folio_963341 - SEP 2024.pdf\n",
      "✅ Datos de 'Agua Buena - Declaración_SINADER_folio_963341 - SEP 2024.pdf' guardados en 'inten\\Agua Buena - Declaración_SINADER_folio_963341 - SEP 2024.xlsx'.\n",
      "📄 Procesando archivo: Agua Buena - Declaración_SINADER_folio_977385 - OCT 2024.pdf\n",
      "✅ Datos de 'Agua Buena - Declaración_SINADER_folio_977385 - OCT 2024.pdf' guardados en 'inten\\Agua Buena - Declaración_SINADER_folio_977385 - OCT 2024.xlsx'.\n",
      "📄 Procesando archivo: Agua Buena - Declaración_SINADER_folio_990955 - NOV 2024.pdf\n",
      "✅ Datos de 'Agua Buena - Declaración_SINADER_folio_990955 - NOV 2024.pdf' guardados en 'inten\\Agua Buena - Declaración_SINADER_folio_990955 - NOV 2024.xlsx'.\n",
      "✅ Procesamiento completado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar variables del .env\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Definir el modelo LLM\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", openai_api_key=api_key)\n",
    "\n",
    "# Crear el prompt para extraer tablas\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"pdf_content\"],\n",
    "    template=(\n",
    "        \"Extrae las tablas del siguiente texto del PDF y organízalas en un formato tabular JSON. \"\n",
    "        \"Después normaliza el JSON extraído. \"\n",
    "        \"El texto es:\\n{pdf_content} \"\n",
    "        \"Solo devuelve el JSON, sin ```json\\n\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Crear cadena de procesamiento LangChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Ruta de entrada y salida\n",
    "pdf_directory = \"pdf\"\n",
    "output_dir = \"inten\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Función para desanidar JSON de forma recursiva\n",
    "def flatten_json(y, parent_key=\"\", sep=\".\"):\n",
    "    \"\"\"Desanida un JSON recursivamente y devuelve un diccionario plano\"\"\"\n",
    "    items = []\n",
    "    if isinstance(y, list):  # Si es lista, convertir en un diccionario enumerado\n",
    "        y = {str(i): v for i, v in enumerate(y)}\n",
    "\n",
    "    for k, v in y.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_json(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list):\n",
    "            for i, elem in enumerate(v):\n",
    "                if isinstance(elem, (dict, list)):\n",
    "                    items.extend(flatten_json(elem, f\"{new_key}[{i}]\", sep=sep).items())\n",
    "                else:\n",
    "                    items.append((f\"{new_key}[{i}]\", elem))\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Procesar archivos PDF\n",
    "for filename in os.listdir(pdf_directory):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        filepath = os.path.join(pdf_directory, filename)\n",
    "        print(f\"📄 Procesando archivo: {filename}\")\n",
    "        \n",
    "        try:\n",
    "            loader = PyPDFLoader(filepath)\n",
    "            documents = loader.load()\n",
    "\n",
    "            # Combinar contenido de páginas\n",
    "            pdf_text = \" \".join([doc.page_content for doc in documents])\n",
    "\n",
    "            # Obtener tablas desde el modelo LLM\n",
    "            response = chain.run(pdf_content=pdf_text)\n",
    "\n",
    "            try:\n",
    "                data = json.loads(response)\n",
    "\n",
    "                # 🔹 Si el JSON es una lista, convertirla en un diccionario antes de continuar\n",
    "                if isinstance(data, list):\n",
    "                    data = {str(i): v for i, v in enumerate(data)}\n",
    "\n",
    "                flattened_data = flatten_json(data)\n",
    "\n",
    "                # Convertir a DataFrame\n",
    "                df_normalized = pd.DataFrame([flattened_data])\n",
    "\n",
    "                # Nombre del archivo Excel para este PDF\n",
    "                excel_filename = filename.replace(\".pdf\", \".xlsx\")\n",
    "                excel_filepath = os.path.join(output_dir, excel_filename)\n",
    "\n",
    "                # Guardar en Excel\n",
    "                with pd.ExcelWriter(excel_filepath, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "                    df_normalized.to_excel(writer, sheet_name=\"Datos\", index=False)\n",
    "\n",
    "                print(f\"✅ Datos de '{filename}' guardados en '{excel_filepath}'.\")\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"❌ Error al decodificar JSON para {filename}: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error al procesar {filename}: {e}\")\n",
    "\n",
    "print(\"✅ Procesamiento completado.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
